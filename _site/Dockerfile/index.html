<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Dockerfile | Platform Operations</title>

    <!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Dockerfile | Platform Operations</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Dockerfile" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Platform Ops, Articles from a platform engineer on Fullstack Development, Application Architecture, DevOps, Cloud Ops, Platform Ops, Docker, Dockerization, Containerisation, CICD Tools, Jenkins, Git, Gitlabs, Distributed Databases configuration, application zero downtime, reverse proxy, NGXIN and it covers each and every area of the application development and operations in the cloud." />
<meta property="og:description" content="Platform Ops, Articles from a platform engineer on Fullstack Development, Application Architecture, DevOps, Cloud Ops, Platform Ops, Docker, Dockerization, Containerisation, CICD Tools, Jenkins, Git, Gitlabs, Distributed Databases configuration, application zero downtime, reverse proxy, NGXIN and it covers each and every area of the application development and operations in the cloud." />
<link rel="canonical" href="http://0.0.0.0:4000/Dockerfile/" />
<meta property="og:url" content="http://0.0.0.0:4000/Dockerfile/" />
<meta property="og:site_name" content="Platform Operations" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-26T00:00:00-05:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://0.0.0.0:4000/assets/images/logo.png"}},"headline":"Dockerfile","dateModified":"2019-08-26T00:00:00-05:00","description":"Platform Ops, Articles from a platform engineer on Fullstack Development, Application Architecture, DevOps, Cloud Ops, Platform Ops, Docker, Dockerization, Containerisation, CICD Tools, Jenkins, Git, Gitlabs, Distributed Databases configuration, application zero downtime, reverse proxy, NGXIN and it covers each and every area of the application development and operations in the cloud.","datePublished":"2019-08-26T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/Dockerfile/"},"url":"http://0.0.0.0:4000/Dockerfile/","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/logo.png">

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css"
        integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">

    <link rel="stylesheet" href="/assets/css/bootstrap.css">

    <link rel="stylesheet" href="/assets/css/theme.css">
    <link rel="stylesheet" href="/assets/css/custom.css">

    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
        integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
        crossorigin="anonymous"></script>
</head>

<body>
  <nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top">
    <a class="navbar-brand font-weight-bolder mr-3" href="/index.html"><img style="height: 50px;"
            src="/assets/images/logo.png"></a>
    <button class="navbar-light navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsDefault"
        aria-controls="navbarsDefault" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarsDefault">
        <ul class="navbar-nav mr-auto align-items-center">
            <script src="/assets/js/lunr.js"></script>

<script>
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 1000 );
        $( "body" ).removeClass( "modal-open" );
    });
});
    

var documents = [{
    "id": 0,
    "url": "http://0.0.0.0:4000/about.html",
    "title": "About",
    "body": "{{site. description}} Features Containerising the following  {% for tech in site. article-catergories %}   {{tech}}  {% endfor %} Made withPintereso Jekyll Theme. ! {% include buy-me-a-coffee. html %} "
    }, {
    "id": 1,
    "url": "http://0.0.0.0:4000/categories.html",
    "title": "Categories",
    "body": "        Categories          {% include categories-list. html %}          {% for category in site. categories %}       # {{ category[0] }}:         {% assign pages_list = category[1] %}    {% for post in pages_list %}     {% if post. title != null %}       {% if group == null or group == post. group %}        {% include card-post. html %}       {% endif %}     {% endif %}    {% endfor %}    {% assign pages_list = nil %}    {% assign group = nil %}  {% endfor %}    "
    }, {
    "id": 2,
    "url": "http://0.0.0.0:4000/contact.html",
    "title": "Contact",
    "body": "  Please send your message to {{site. name}}. We will reply as soon as possible!   "
    }, {
    "id": 3,
    "url": "http://0.0.0.0:4000/home.html",
    "title": "Home",
    "body": "                              Platform Operations                      Anything and Everything                                 Learn                                 Create                                 Containerize                                 Automate                                     What is Platform Ops:     Execution is more important than Planning. Planning is more important than Ideas           Applicable for creating custom docker image or containerising the application.               Platform Operations, will help you containerise all the the ideas, if we haven't covered as part of our      articles, raise your hand with an issue on       platform-ops:                   Unlimited Articles, Unlimited Fun:       Check out what you can do with platform-ops!                             {% include article-catergories. html %}                                      Platform Operations will be working on creating tutorials and practical implementation of the            dockerisation            of any application. Tutorials created here are purely example based, which will help you            dockerize your            application and run it as a container.                                 Platform Ops covers the topics from different areas of development and operations. We expect the            feedback or            suggestions to create the new tutorials which are missing. Platform Ops coverwith the following            technologies.                           {% include technologies. html %}            "
    }, {
    "id": 4,
    "url": "http://0.0.0.0:4000/",
    "title": "Pintereso Free Jekyll Theme",
    "body": "   Explore     {% include categories-list. html %}         {% for post in paginator. posts reversed %}   {% include card-post. html %}   {% endfor %}          {% if paginator. total_pages &gt; 1 %}       {% if paginator. previous_page %}    &laquo; Prev    {% else %}    &laquo; Prev    {% endif %}    {% for page in (1. . paginator. total_pages) %}    {% if page == paginator. page %}    {{ page }}    {% elsif page == 1 %}    {{ page }}    {% else %}    {{ page }}    {% endif %}    {% endfor %}    {% if paginator. next_page %}    Next &raquo;    {% else %}    Next &raquo;    {% endif %}      {% endif %}   "
    }, {
    "id": 5,
    "url": "http://0.0.0.0:4000/license.html",
    "title": "License",
    "body": "Our website is licensed under MIT and designed &amp; developed with by Jinna Balu. You can do anything you want with our content (use it for personal but not for commercial) as long as your action doesn’t hurt individual identity. A small donation is accepted in exchange. We appreciate your support, with each donation, we can dedicate time to releasing even more information about farmers, crops, and stores. {% include buy-me-a-coffee. html %} Terms of Use:  Third party resources upon which our website is built, are not part of this license. Their license and credits can be found in their respective files.  To modify the content or if you have any issue with the content or for any questions or concerns regarding the license, please contact us here.  Support is not included. "
    }, {
    "id": 6,
    "url": "http://0.0.0.0:4000/privacy-policy.html",
    "title": "Privacy Policy",
    "body": "”{{site. name}}” takes your privacy seriously. To better protect your privacy we provide this privacy policy notice explaining the way your personal information is collected and used. Collection of Routine Information: This website track basic information about their visitors. This information includes, but is not limited to, IP addresses, browser details, timestamps and referring pages. None of this information can personally identify specific visitor to this website. The information is tracked for routine administration and maintenance purposes. Cookies: Where necessary, this website uses cookies to store information about a visitor’s preferences and history in order to better serve the visitor and/or present the visitor with customized content. Advertisement and Other Third Parties: Advertising partners and other third parties may use cookies, scripts and/or web beacons to track visitor activities on this website in order to display advertisements and other useful information. Such tracking is done directly by the third parties through their own servers and is subject to their own privacy policies. This website has no access or control over these cookies, scripts and/or web beacons that may be used by third parties. Learn how to opt out of Google’s cookie usage. Links to Third Party Websites: We have included links on this website for your use and reference. We are not responsible for the privacy policies on these websites. You should be aware that the privacy policies of these websites may differ from our own. Security: The security of your personal information is important to us, but remember that no method of transmission over the Internet, or method of electronic storage, is 100% secure. While we strive to use commercially acceptable means to protect your personal information, we cannot guarantee its absolute security. Changes To This Privacy Policy: This Privacy Policy is effective and will remain in effect except with respect to any changes in its provisions in the future, which will be in effect immediately after being posted on this page. We reserve the right to update or change our Privacy Policy at any time and you should check this Privacy Policy periodically. If we make any material changes to this Privacy Policy, we will notify you either through the email address you have provided us, or by placing a prominent notice on our website. Contact Information: For any questions or concerns regarding the privacy policy, please contact us here. "
    }, {
    "id": 7,
    "url": "http://0.0.0.0:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 8,
    "url": "http://0.0.0.0:4000/page2/",
    "title": "Pintereso Free Jekyll Theme",
    "body": "   Explore     {% include categories-list. html %}         {% for post in paginator. posts reversed %}   {% include card-post. html %}   {% endfor %}          {% if paginator. total_pages &gt; 1 %}       {% if paginator. previous_page %}    &laquo; Prev    {% else %}    &laquo; Prev    {% endif %}    {% for page in (1. . paginator. total_pages) %}    {% if page == paginator. page %}    {{ page }}    {% elsif page == 1 %}    {{ page }}    {% else %}    {{ page }}    {% endif %}    {% endfor %}    {% if paginator. next_page %}    Next &raquo;    {% else %}    Next &raquo;    {% endif %}      {% endif %}   "
    }, {
    "id": 9,
    "url": "http://0.0.0.0:4000/Try-in-Play-With-Docker-Labs/",
    "title": "Adding Try in PWD button to README file",
    "body": "2019/09/10 - The “Try in PWD” actually supports to deploy any stack file that’s available on the web. In the stack parameter you can either add a relative path of a stack in the stacks repo or a URL. Create the button with the following script: [![Try in PWD](https://cdn. rawgit. com/play-with-docker/stacks/cff22438/assets/images/button. png)](http://play-with-docker. com?stack=https://&lt;my_stack_url&gt;) Example to run wordpress as a container with the follwoingThis is how the script looks like [![Try in PWD](https://cdn. rawgit. com/play-with-docker/stacks/cff22438/assets/images/button. png)](http://play-with-docker. com?stack=https://raw. githubusercontent. com/JinnaBalu/wordpress/master/docker-compose-wordpress-mysql. yml) This is how the button look like Additionally we wanted to have everything in one place (button + stacks) so users can click on the button and go to the Play with Docker "
    }, {
    "id": 10,
    "url": "http://0.0.0.0:4000/Dockerise-Wordpress/",
    "title": "What is containerization and How does docker helps for a dev and prod environments",
    "body": "2019/09/10 - In the beginning let me give you my short and concise definition of the problem Docker is built to solve. So we’ll start from there and move on step by step. What problem does docker solve?: This is the fundamental question of everyone who wants to start out with Docker. Let’s answer the question in the clearest and simplest way possible, with everyday words, not Docker terminology. What problem does Docker solve? Docker solves the problem of having identical environments across various stages of development and having isolated environments for your individual applications. The problem itself is as old as software development. Environment setup and management is a tedious task in every project. In the old days we used custom scripts for that. We used to host various different applications on the same physical machine without any virtualization. It was usually a configuration nightmare to juggle with environment variables, trying to keep applications independently configurable or using two different versions of the same technology (like Java) on the same machine. It used to be common practice to run your production applications on dedicated machines, while development or test environments were clattered with a lot of different applications to save hardware cost. In these cases your development and test servers were configured much differently than your production server. Our infrastructure teams used to create different environment scripts for different stages, like development, test, staging and production. These environments were not identical, just mostly similar. On top of all this, we used to do our local development and unit testing on Windows machines, while all other stages were run on Unix systems. Working like this was not impossible, but it was a costly, time consuming effort to manage these environments with a lot of inherent risk that caused a lot of quality issues in all stages. Docker provides a solution to this problem. "
    }, {
    "id": 11,
    "url": "http://0.0.0.0:4000/Dockerise-html-page/",
    "title": "Deploy Static HTML Website as Container",
    "body": "2019/08/26 - {% include docker-prerequisites. md %} Create a sample static app: &lt;!DOCTYPE html&gt;&lt;html lang= en &gt;&lt;head&gt; &lt;title&gt;Platform Ops&lt;/title&gt; &lt;meta charset= utf-8 &gt; &lt;meta name= viewport  content= width=device-width, initial-scale=1 &gt; &lt;link rel= stylesheet  href= https://maxcdn. bootstrapcdn. com/bootstrap/3. 4. 0/css/bootstrap. min. css &gt; &lt;script src= https://ajax. googleapis. com/ajax/libs/jquery/3. 4. 1/jquery. min. js &gt;&lt;/script&gt; &lt;script src= https://maxcdn. bootstrapcdn. com/bootstrap/3. 4. 0/js/bootstrap. min. js &gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class= jumbotron &gt; &lt;h1&gt;Platform Ops&lt;/h1&gt;  &lt;p&gt;Anything and Everything as container&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;Option #1Deploy Static app as container with nginx image: Create a docker-compose. yml version:  3 services: static-app:  image: nginx:1. 17  container_name: platform-ops  volume:   - . /usr/share/nginx/html  deploy:   replicas: 1  ports:   - 80:80 RUN the containerdocker-compose up -dOption #2Create a Dockerfile to create a custom image: Create a Dockerfile with NGINX as base image, copying the static content of the website. FROM nginx:1. 17COPY . /usr/share/nginx/html FROM nginx:1. 17 - Base image of the container, with the version 1. 17 COPY . /usr/share/nginx/html - Copying the content of the current directory . to /usr/share/nginx/html location of the container. Create a docker image: Docker CLI will use the Dockerfile, to create the docker image. Here is the docker build command to create the image docker build -t platform-ops-static . By default it create a image with latest tag. OR To create the docker image with tag as follows docker build -t platform-ops-static:v1 .  platform-ops-static - image name v1 - tag to maintain the version between the imagesDeploy Static app as container: Create a docker-compose. yaml version:  3 services: static-app:  image: platform-ops-static  container_name: platform-ops  deploy:   replicas: 1  ports:   - 80:80 RUN the containerdocker-compose up -d"
    }, {
    "id": 12,
    "url": "http://0.0.0.0:4000/Dockerfile/",
    "title": "Dockerfile",
    "body": "2019/08/26 - "
    }, {
    "id": 13,
    "url": "http://0.0.0.0:4000/Docker-Image-Layers/",
    "title": "Deep",
    "body": "2019/08/26 - "
    }, {
    "id": 14,
    "url": "http://0.0.0.0:4000/Single-Node-Couchbase-Container/",
    "title": "Deploy Single Node Couchbase on Docker Compose",
    "body": "2019/08/22 - "
    }, {
    "id": 15,
    "url": "http://0.0.0.0:4000/Couchbase-Intro/",
    "title": "Couchbase Introduction",
    "body": "2019/08/22 - What is Couchbase Server?: I won’t spend the time to explain the intro material here but wanted to correctly identify brief explanation about the basics and we will work on running the couchbase as a container. Couchbase is an open-source distributed multi-node-model NoSQL document-oriented database Multinode cluster. Features that are provided by the Couchbase at any scale are  Elastic Scalability Consistent High Performance Always-On Availability Multi-Data Center Deployment Simple and Powerful Administration Enterprise-grade SecurityCouchbase Server is designed to provide easy-to-scale key-value or JSON document access with low latency and high sustained throughput In Multi node cluster every Couchbase node consists of a data service, index service, query service, and cluster manager component. Couchbase is normally a CP type system meaning it provides Consistency and partition tolerance, or it can be set up as an AP system with multiple clusters, of Eric Brewer’s CAP theorem Now the question, how do we run Couchbase as a container, Following are the Articles related to the containerisation of couchbase.  Run Single Node Couchbase Container"
    }, {
    "id": 16,
    "url": "http://0.0.0.0:4000/Steps-to-install-a-Go-Daddy-SSL-Certificate-with-NGINX/",
    "title": "Steps to install a Go Daddy SSL Certificate with NGINX",
    "body": "2019/07/09 - Step1: Generate a CSR and Private Key: Before purchasing the certificate we have to generate the CSR(Certificate Signing Request) and key files. You can generate CSR and . key with openssl. Here is the example commad with sample domain. openssl req -newkey rsa:2048 -nodes -keyout [KEY_FILE_NAME]. key -out [CSR_FILE_NAME]. csrKEY_FILE_NAME, this is a private key file used in nginx configuration. CSR_FILE_NAME, CSR file used for generating the crt file from Godaddy. Following is the example of the platform-ops. key and platform-ops. csr: openssl req -newkey rsa:2048 -nodes -keyout platform-ops. key -out platform-ops. csr platform-ops. key - KEY_FILE_NAME  platform-ops. csr - CSR_FILE_NAME  Here is the terminal sample outputbalu@master-node:~/work/Courses/platformops. github. io$ openssl req -newkey rsa:2048 -nodes -keyout platform-ops. key -out platform-ops. csrGenerating a 2048 bit RSA private key. . . . . . . . . +++. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . +++writing new private key to 'platform-ops. key'-----You are about to be asked to enter information that will be incorporatedinto your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '. ', the field will be left blank. -----Country Name (2 letter code) [AU]:INState or Province Name (full name) [Some-State]:TelanganaLocality Name (eg, city) []:MedakOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Platform OpsOrganizational Unit Name (eg, section) []:MedakCommon Name (e. g. server FQDN or YOUR name) []:Jinna BaluEmail Address []:jinna. balu@platform-ops. comPlease enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:An optional company name []:Platform Ops  This will generate two files, platform-ops. key and platform-ops. csr. you can copy the . csr file content to request for the SSL Certificate. To view the content of the platform-ops. csr use the following command. Now you can purchase your certificate. You will need to copy and paste your platform-ops. csr certificate to send your request for a SSL Certificate. Use this command to print your file: cat platform-ops. csrSteps 2: Get an SSL certificate: Buy SSL and show visitors you’re trustworthy and authentic. Godaddy provides the ssl certificate with the following types.  Protect one website Protect multiple websites Protect all sub domainsGo for something that best suits your needs purchase the certificate. This tutorial is based on the first one but I’m sure you can use it for all of them. Clear steps defined for purchasing and activating the ssl in SSL Certificates Help godaddy official docs. Step 3: Request an SSL certificate and download: GoDaddy now verifies that you control the domain. You will receive an email as soon as your SSL certificate will be issued with a link to download it. Open that link. Select Apache from the Server type dropdown menu and download the ZIP archive. It should contain two . crt files: Your SSL Certificate with a random name (Ex. 93rfs8dhf834hts. crt)The GoDaddy intermediate certificate bundle (Ex. gd_bundle-g2-g1. crt) The certificate is now ready to be installed on your NGINX Generate single chained certificate: With Nginx, if your Certificate Authority (CA) included an intermediate certificate, you must create a single chained certificate file that contains your certificate and the CA’s intermediate certificates. CertificatesOnes you have generated, downloaded and extracted the certificate zip, you will find 2 files in it:  gd_bundle-g2-g1. crt Intermediate Certificate RANDOM_NUM. crt Your SSL CertificateCreating single chained certificateCreate a single “chained” certificate file that contains your certificate and the CA’s intermediate certificates. cat &lt;RANDAM_NAME_SSL CERTIFICAT&gt;. crt &lt;GD_BUNDLE_OR_SSL_CERTIFICATE&gt;. crt &gt; &lt;NEW_FILE_NAME&gt;. crt# Examplecat 93rfs8dhf834hts. crt gd_bundle-g2-g1. crt &gt; platform-ops. crtOPTIONALYou can validate your certificates using your key file.    Check a certificate and return information about it(Signing authority, expiration date, etc. )   openssl x509 -in server. crt -text -noout     Check the SSL key and verify the consistency.   openssl rsa -in server. key -check     Verify the CSR and print CSR data filled in when generating the CSR.   openssl req -text -noout -verify -in server. csr     The following two commands will print out md5 sums of the certificate and key. These sums can be compared to verify that the certificate and key match.   openssl x509 -noout -modulus -in server. crt| openssl md5               `openssl rsa -noout -modulus -in server. key     openssl md5          Step 4: Run NGINX with SSL:  Create a isolated directory for runing the nginx to do run the followingmkdir nginx-configuration/cd nginx-configuration/      Generate the basic . conf for ssl configuration   cat &lt;&lt;\EOF &gt;&gt; nginx. confuser root;events {  worker_connections 1024;}http {  include      mime. types;  . . . . . . . . .   . . . . . . . . . .   server {   listen 80;   server_name platform-ops. tech;   return 301 https://$host$request_uri;   access_log off;   error_log /var/log/nginx/error. log error;  }  server {    listen 443 ssl;    server_name platform-ops. tech;    root /usr/share/nginx/html;    ssl_certificate  /etc/nginx/ssl/platform-ops. crt;    ssl_certificate_key  /etc/nginx/ssl/ platform-ops. key;    . . . . . .     . . . . . .     location / {      . . . . .       . . .     }  }} Generate the docker-compose files for nginxcd nginx-configuration/cat &lt;&lt;\EOF &gt;&gt; docker-compose. ymlversion: '3'services: proxy:  image: nginx:latest  container_name: nginx_proxy  volumes:   -  . /nginx. conf:/etc/nginx/nginx. conf:ro    -  . /certs:/etc/nginx/ssl:ro    -  . /html:/usr/share/nginx/html:ro    -  $PWD/logs/nginx:/var/log/nginx   restart: always  ports:   -  80:80    -  443:443 EOF Run nginx docker containerdocker-compose up -d"
    }, {
    "id": 17,
    "url": "http://0.0.0.0:4000/Docker-Issues/",
    "title": "Docker Issues",
    "body": "2019/07/09 - Docker issues: could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the networkSolution : docker network prune "
    }, {
    "id": 18,
    "url": "http://0.0.0.0:4000/Elasticsearch-Issues/",
    "title": "Elasticsearch - Issues",
    "body": "2019/06/30 - "
    }, {
    "id": 19,
    "url": "http://0.0.0.0:4000/Elasticsearch-Basics/",
    "title": "Elasticsearch - Basics of Elasticsearch",
    "body": "2019/06/30 - Elasticsearch is the distributed search and analytics engine at the heart of the Elastic Stack. Logstash and Beats facilitate collecting, aggregating, and enriching your data and storing it in Elasticsearch. Features include::  Distributed and Highly Available Search Engine.  Each index is fully sharded with a configurable number of shards.  Each shard can have one or more replicas.  Read / Search operations performed on either one of the replica shard.  Multi Tenant with Multi Types.  Support for more than one index.  Support for more than one type per index before 2. 4. 1 Index level configuration (number of shards, index storage, …).  Various set of APIs HTTP RESTful API Native Java API.  All APIs perform automatic node operation rerouting.  Document oriented No need for upfront schema definition.  Schema can be defined per type for customization of the indexing process.  Reliable, Asynchronous Write Behind for long term persistency.  (Near) Real Time Search.  Built on top of Lucene Each shard is a fully functional Lucene index All the power of Lucene easily exposed through simple configuration / plugins.  Per operation consistency Single document level operations are atomic, consistent, isolated and durable.  Open Source under the Apache License, version 2 (“ALv2”)Requirements: You need to have a recent version of Java installed. See the “Setup”:http://www. elastic. co/guide/en/elasticsearch/reference/current/setup. html#jvm-version page for more information. "
    }, {
    "id": 20,
    "url": "http://0.0.0.0:4000/What-is-Arachni/",
    "title": "Arachni - Vulnerability Assessment & Penetration Testing Tool",
    "body": "2019/06/27 - Arachni1 Introduction:: Arachni is a feature-full, modular, high-performance Ruby framework aimed towards helping penetration testers and administrators evaluate the security of modern web applications. Recommended system requirements: Operating systems: Linux (32bit or 64bit), Mac OS X (64bit), Windows (64bit)RAM: 2GB of available memory. Storage: 10GB of available disk space. Optional: PostgreSQL server for the WebUI — by default SQLite3 is used (included in the packages). PostgreSQL is preferred when dealing with larger workloads, for configuration instructions please see the WebUI Wiki. Prior to running scans, it is recommended that you consult the scan optimization guide, as there are several options you can use to significantly increase performance and/or limit resource utilization. 2. Running arachni as a container: 3. Running as a self contained package: 4. Using Arachni Web UI: "
    }, {
    "id": 21,
    "url": "http://0.0.0.0:4000/Using-Arachni-Web-UI/",
    "title": "Arachni - Vulnerability Assessment & Penetration Testing Tool",
    "body": "2019/06/27 - Arachni1. Introduction: 2. Running as a container: 3. Running as a self contained package: 4. Using Web UI: As you run arachni successfully, service will be available on http://localhost:9292 or http://HOST_IP:9292  Open the application in the broswer and go to Scans menu and click on New  In start scaning scren fill the form and click on go. Only website url would be more enough to scan through, else use the specified funcationalities to reduce the load    On Successfull scan, you can check with the recent scans, go to scans menu and select recent scan   In this step we have options to download the scaned report in different formats(html, json, marshal, XML, yaml, AFR)  "
    }, {
    "id": 22,
    "url": "http://0.0.0.0:4000/Upgrade-Jenkins/",
    "title": "Jenkins - Upgrade Jenkins",
    "body": "2019/06/27 - Upgrade jenkins latest version   when we see the upgrade availble notifier in jenkins     Jenkins is installed on ubuntu, in /usr/share/jenkins, do the following steps to upgrade  cd /usr/share/jenkinssudo service jenkins stopsudo mv jenkins. war jenkins. war. oldsudo wget https://updates. jenkins-ci. org/latest/jenkins. warsudo service jenkins start Jenkins URL https://updates. jenkins-ci. org/latest/jenkins. war vary between versions available "
    }, {
    "id": 23,
    "url": "http://0.0.0.0:4000/Sed-Command-in-Unix/",
    "title": "Sed Command In Unix",
    "body": "2019/06/27 - SEDSed is a Stream Editor used for modifying the files in unix (or linux) Features of sed: Consider the below file for as example for our practice: $ cat file. txt learn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free osunixlinuxlearn osopen sourceReplacing or substituting string: $ sed &apos;s/unix/linux/&apos; file. txtlearn about sed in linux or linuxlinux commandsstream editor for linux or linux. unix is free oslinuxlinuxlearn osopen sourceHere the s specifies the substitution operation. The / are delimiters. The unix is the search pattern and the linux is the replacement string. By default, the sed command replaces the first occurrence of the pattern in each line and it won’t replace the second, third…occurrence in the line. Replacing the nth occurrence of a pattern in a line: Use the /1, /2 etc flags to replace the first, second occurrence of a pattern in a line. The below command replaces the second occurrence of the word unix with linux in a line $ sed &apos;s/unix/linux/2&apos; file. txtlearn about sed in unix or linuxunix commandsstream editor for linux or unix. linux is free osunixlinuxlearn osopen source$ sed &apos;s/unix/linux/1&apos; file. txtlearn about sed in linux or linuxlinux commandsstream editor for linux or linux. unix is free oslinuxlinuxlearn osopen sourceReplacing all the occurrence of the pattern in a line. : The substitute flag /g (global replacement) specifies the sed command to replace all the occurrences of the string in the line. $ sed &apos;s/unix/linux/g&apos; file. txtlearn about sed in linux or linuxlinux commandsstream editor for linux or linux. linux is free oslinuxlinuxlearn osopen sourceReplacing from nth occurrence to all occurrences in a line. : Use the combination of /1, /2 etc and /g to replace all the patterns from the nth occurrence of a pattern in a line. The following sed command replaces the third, fourth, fifth… “unix” word with “linux” word in a line. $ sed &apos;s/unix/linux/3g&apos; file. txtlearn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free osunixlinuxlearn osopen sourceChanging the slash (/) delimiter: You can use any delimiter other than the slash. As an example if you want to change the web url to another url as $ cat file. txt learn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free osunixlinuxlearn osopen sourcehttps://wwwhttp://https://www$ sed &apos;s/http:\/\//www/&apos; file. txtlearn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free osunixlinuxlearn osopen sourcehttps://wwwwwwhttps://wwwIn this case the url consists the delimiter character which we used. In that case you have to escape the slash with backslash character, otherwise the substitution won’t work. Using too many backslashes makes the sed command look awkward. In this case we can change the delimiter to another character as shown in the below example. $ sed &apos;s|http://|www|&apos; file. txtlearn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free osunixlinuxlearn osopen sourcehttps://wwwwwwhttps://www$ sed &apos;s_http://_www_&apos; file. txtlearn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free osunixlinuxlearn osopen sourcehttps://wwwwwwhttps://wwwUsing &amp; as the matched string: There might be cases where you want to search for the pattern and replace that pattern by adding some extra characters to it. In such cases &amp; comes in handy. The &amp; represents the matched string. $ sed &apos;s/unix/{&amp;}/&apos; file. txtlearn about sed in {unix} or linux{unix} commandsstream editor for linux or {unix}. unix is free os{unix}linuxlearn osopen sourcehttps://wwwhttp://https://www$ sed &apos;s/unix/{&amp;&amp;}/&apos; file. txtlearn about sed in {unixunix} or linux{unixunix} commandsstream editor for linux or {unixunix}. unix is free os{unixunix}linuxlearn osopen sourcehttps://wwwhttp://https://wwwUsing \1,\2 and so on to \9: The first pair of parenthesis specified in the pattern represents the \1, the second represents the \2 and so on. The \1,\2 can be used in the replacement string to make changes to the source string. As an example, if you want to replace the word “unix” in a line with twice as the word like “unixunix” use the sed command as below. $ sed &apos;s/\(unix\)/\1\1/&apos; file. txtlearn about sed in unixunix or linuxunixunix commandsstream editor for linux or unixunix. unix is free osunixunixlinuxlearn osopen sourcehttps://wwwhttp://https://wwwThe parenthesis needs to be escaped with the backslash character. Another example is if you want to switch the words “unixlinux” as “linuxunix”, the sed command is $ sed &apos;s/\(unix\)\(linux\)/\2\1/&apos; file. txtlearn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free osunixlinuxlearn osopen sourcehttps://wwwhttp://https://wwwAnother example is switching the first three characters in a line $ sed &apos;s/^\(. \)\(. \)\(. \)/\3\2\1/&apos; file. txtaelrn about sed in unix or linuxinux commandsrtseam editor for linux or unix. unix is free osinuxniluxaelrn osepon sourcetthps://wwwtthp://tthps://wwwDuplicating the replaced line with /p flag: The /p print flag prints the replaced line twice on the terminal. If a line does not have the search pattern and is not replaced, then the /p prints that line only once. $ sed &apos;s/unix/linux/p&apos; file. txtlearn about sed in linux or linuxlearn about sed in linux or linuxlinux commandslinux commandsstream editor for linux or linux. unix is free osstream editor for linux or linux. unix is free oslinuxlinuxlinuxlearn osopen sourcehttps://wwwhttp://https://wwwPrinting only the replaced lines: Use the -n option along with the /p print flag to display only the replaced lines. Here the -n option suppresses the duplicate rows generated by the /p flag and prints the replaced lines only one time. $ sed -n &apos;s/unix/linux/p&apos; file. txtlearn about sed in linux or linuxlinux commandsstream editor for linux or linux. unix is free oslinux Note : If you use -n alone without /p, then the sed does not print anything. Running multiple sed commands. : You can run multiple sed commands by piping the output of one sed command as input to another sed command. $ sed &apos;s/unix/linux/&apos; file. txt| sed &apos;s/os/system/&apos;learn about sed in linux or linuxlinux commandsstream editor for linux or linux. unix is free systemlinuxlinuxlearn systemopen sourcehttps://wwwhttp://https://wwwSed provides -e option to run multiple sed commands in a single sed command. The above output can be achieved in a single sed command as shown below. $ sed -e &apos;s/unix/linux/&apos; -e &apos;s/os/system/&apos; file. txtlearn about sed in linux or linuxlinux commandsstream editor for linux or linux. unix is free systemlinuxlinuxlearn systemopen sourcehttps://wwwhttp://https://wwwReplacing string on a specific line number. : You can restrict the sed command to replace the string on a specific line number. An example is $ sed &apos;4 s/unix/linux/&apos; file. txtlearn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free oslinuxlinuxlearn osopen sourcehttps://wwwhttp://https://wwwReplacing string on a range of lines. : You can specify a range of line numbers to the sed command for replacing a string. $ sed &apos;1,3 s/unix/linux/&apos; file. txtlearn about sed in linux or linuxlinux commandsstream editor for linux or linux. unix is free osunixlinuxlearn osopen sourcehttps://wwwhttp://https://wwwHere the sed command replaces the lines with range from 1 to 3. Another example is $ sed &apos;2,$ s/unix/linux/&apos; file. txtlearn about sed in unix or linuxlinux commandsstream editor for linux or linux. unix is free oslinuxlinuxlearn osopen sourcehttps://wwwhttp://https://wwwHere $ indicates the last line in the file. So the sed command replaces the text from second line to last line in the file. Replace on a lines which matches a pattern. : You can specify a pattern to the sed command to match in a line. If the pattern match occurs, then only the sed command looks for the string to be replaced and if it finds, then the sed command replaces the string. $ sed &apos;/linux/ s/unix/centos/&apos; file. txtlearn about sed in centos or linuxunix commandsstream editor for linux or centos. unix is free osunixlinuxlearn osopen sourcehttps://wwwhttp://https://wwwDeleting lines. : You can delete the lines a file by specifying the line number or a range or numbers. $ sed &apos;2 d&apos; file. txtlearn about sed in unix or linuxstream editor for linux or unix. unix is free osunixlinuxlearn osopen sourcehttps://wwwhttp://https://www$ sed &apos;5,$ d&apos; file. txtlearn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free osunixDuplicating lines: You can make the sed command to print each line of a file two times. $ sed &apos;p&apos; file. txtlearn about sed in unix or linuxlearn about sed in unix or linuxunix commandsunix commandsstream editor for linux or unix. unix is free osstream editor for linux or unix. unix is free osunixunixlinuxlinuxlearn oslearn osopen sourceopen sourcehttps://https://wwwwwwhttp://http://https://wwwhttps://wwwSed as grep command: You can make sed command to work as similar to grep command. $ sed -n &apos;/unix/ p&apos; file. txtlearn about sed in unix or linuxunix commandsstream editor for linux or unix. unix is free osunixHere the sed command looks for the pattern “unix” in each line of a file and prints those lines that has the pattern. You can also make the sed command to work as grep -v, just by using the reversing the sed with NOT (!). $ grep -v 'unix' file. txt$ sed -n &apos;/unix/ !p&apos; file. txtlinuxlearn osopen sourcehttps://wwwhttp://https://wwwThe ! here inverts the pattern match Add a line after a match. : sed '/unix/ a  Add a new line ' file. txtAdd a line before a match: sed '/unix/ i  Add a new line ' file. txtAdd a line after a match. : sed '/unix/ a  Add a new line ' file. txtChange a line: sed '/unix/ c  Change line ' file. txtTransform like tr command: sed 'y/ul/UL/' file. txt"
    }, {
    "id": 24,
    "url": "http://0.0.0.0:4000/Schedule-a-Build-in-Jenkins/",
    "title": "Jenkins - Schedule",
    "body": "2019/06/27 - Schedule:  Create a job Configure Build Triggers –&gt; Build Periodically –&gt; Schedule, periodically build you can schedule the build definition by the date or day of the week and the time to execute the build  Jenkins schedule format  Schedule Format:   Schedule formats are syntax of cron (with minor differences). Specifically, each line consists of 5 fields separated by TAB or whitespace:     MINUTE HOUR DOM MONTH DOW          MINUTE	Minutes within the hour (0–59)           HOUR	The hour of the day (0–23)           DOM	The day of the month (1–31)           MONTH	The month (1–12)           DOW	The day of the week (0–7) where 0 and 7 are Sunday.       To specify multiple values for one field, the following operators are available. In the order of precedence,    specifies all valid values          M-N specifies a range of values           M-N/X or */X steps by intervals of X through the specified range or whole valid range           A,B,. . . ,Z enumerates multiple values          Jenkins schedule format is nothing but a cron schedule expression  Examples:       Schedule Description   Schedule command         every hour   H * * * *       every 20 minutes   H/20 * * * *       every 20 minutes 2am to 11pm   H/20 5-23 * * *       every 20 minutes, work time/days (8am-6pm, MON-FRI) only   H/20 8-18 * * 1-5       every hour MON-WED and FRI only   H * * * 1-3,5       every hour, weekends in April and December   H * * 4,12 *       Build at 8. 30am on July 4   30 8 4 7 *       every ten minutes in the first half of every hour   H(0-29)/10 * * * *       every fifteen minutes   H/15 * * * *       once every two hours at 45 minutes past the hour starting at 9:45 AM and finishing at 3:45 PM every weekday   45 9-16/2 * * 1-5       once in every two hours slot between 9 AM and 5 PM every weekday   H H(9-16)/2 * * 1-5       once a day on the 1st and 15th of every month except December   H H 1,15 1-11 *   Schedule Alias: Jenkins predefined aliases to schedule build: @hourly, @daily, @weekly, @monthly, @midnight       Schedule Alias   Schedule Description   Schedule command         @hourly   Build every hour at the beginning of the hour   0 * * * *       @daily   @midnight	Build every day at midnight   0 0 * * *       @weekly   Build every week at midnight on Sunday morning   0 0 * * 0       @monthly   Build every month at midnight of the first day of the month   0 0 1 * *   Jenkins multiple schedules:  Schedule one - every week before weekend starts 30 16 * * 5 Schedule two - every work day 30 9 * * 1-5Now schedule both schedules together with  30 9 * * 1-5  30 16 * * 5Time zone specification: Periodic tasks are normally executed at the scheduled time in the time zone of the Jenkins master JVM (currently Etc/UTC). This behavior can optionally be changed by specifying an alternative time zone in the first line of the field. Time zone specification starts with TZ=, followed by the ID of a time zone. We can set the time zone for the schedules with TZ, allows to schedule job according to the time zone Complete example of a schedule with a time zone specification:   TZ=Europe/London  # This job needs to be run in the morning, London time  H 8 * * *  # Butlers do not have a five o'clock, so we run the job again  H(0-30) 17 * * *Jenkins Supported Time Zones "
    }, {
    "id": 25,
    "url": "http://0.0.0.0:4000/SSL-configuration/",
    "title": "SSL - Secure Sockets Layer",
    "body": "2019/06/27 - What is SSL?SSL (Secure Sockets Layer) is the standard security technology for establishing an encrypted link between a web server and a browser. This link ensures that all data passed between the web server and browsers remain private and integral. SSL is an industry standard and is used by millions of websites in the protection of their online transactions with their customers.  Step 1. Buy the SSL from the provider,: In current docs I exaplin about godaddy, follow Step 2. Generate CSR: How you generate a . csr depends on the type of certificate you’re requesting and your operating system.  SSH into your server Gnerate crt using openssl with following command  openssl req -new -newkey rsa:2048 -nodes -keyout example. key -out example. csr    Here is the godaddy docsStep 3. Generate . crt file from the SSL Provider: Above step will generate the csr file copy that into the ssl provider and get the . crt file which can be used for the SSL management of the website. Here is how we can generate . crt file:    Next go to the SSL management section of your GoDaddy account and click “Manage” next to the certificate you want to use.  Click on the “Re-Key” and cut and paste the results of the CSR above into the re-key request. Finish the process completely.     Steps for godaddy SSL certificate configuration here     After generating the . crt file, you will download a zipfile contrains the  Step 4. Concatinate the intermidiate and budle . crt files to generate: A common practice, then, is to bundle these all up into one file – your certificate, then the signing certificates. But since they aren’t easily distinguished, it sometimes happens that someone accidentally puts them in the other order – signing certs, then the final cert – without noticing. In that case, your cert will not match your key. cat certificate. crt ca_bundle. crt &gt; bundle_chained. crtHere is the related issues with X509_check_private_key:key values mismatch, stackoverflow answer Here is the example for nginx ssl certificate conf server {  listen       443 ssl;  server_name     www. example. com;  ssl_certificate   bundle_chained. crt;  ssl_certificate_key example. key;  . . . }"
    }, {
    "id": 26,
    "url": "http://0.0.0.0:4000/Running-as-a-self-contained-package/",
    "title": "Arachni - Vulnerability Assessment & Penetration Testing Tool",
    "body": "2019/06/27 - Arachni1. Introduction: 2. Running as a container: 3. Running as a self contained package: Download Self contained Arachni Package for Linux/MacOS/Windows here Linux:    To use Arachni run the executables under “bin/”.     To launch the Web interface: bin/arachni_web     Default account details:          Administrator: E-mail address: admin@admin. admin Password:    administrator           User: E-mail address: user@user. user Password:    regular_user          For a quick scan: via the command-line interface: bin/arachni http://test. com     To see the available CLI options: bin/arachni -h     For detailed documentation click here  4. Using Web UI: "
    }, {
    "id": 27,
    "url": "http://0.0.0.0:4000/Running-arachni-as-a-container/",
    "title": "Arachni - Vulnerability Assessment & Penetration Testing Tool",
    "body": "2019/06/27 - Arachni1. Introduction: 2. Running as a container: Environment variables: | Name | Default | Options || ————- | ————- | ————- || SERVER_ROOT_PASSWORD | arachni | any || ARACHNI_USERNAME | arachni | any || ARACHNI_PASSWORD | password | any || DB_ADAPTER | sqlite | sqlite, postgresql || DB_HOST | {empty} | any || DB_NAME | {empty} | any || DB_USER | {empty} | any || DB_PASS | {empty} | any | Run the docker container: docker run -d \ -p 222:22 \ -p 7331:7331 \ -p 9292:9292 \ --name arachni \ arachni/arachni:latestSSH: ssh -p 222 root@docker-machineIP with default password is  arachni  Web endpoint can be access as:: http://${docker-machineIP}:9292  Web-UI Admin’s username and passwordusername: admin@admin. admin password: administrator  Web-UI User’s username and passwordusername: user@user. user password: regular_user RESTful API endpoint will be: http://${docker-machineIP}:7331 Customise container with:  RUNdocker run -d \ -p 222:22 \ -p 7331:7331 \ -p 9292:9292 \ --name arachni \ -e SERVER_ROOT_PASSWORD= DockerArachniPWD  \ -e ARACHNI_PARAMS= --authentication-username arachni --authentication-password Pass123 --only-positives  \ arachni:1. 4 SSHssh -p 222 root@docker-machineIP with password is  DockerArachniPWD   RESTful API customized username and passwordusername: arachni password: Pass123 Archani with Database adopter as postgresSQL: RUN using docker run command: docker run -d \ -e  DB_ADAPTER=postgresql  \ -e  DB_HOST=sample_host  \ -e  DB_NAME=sample_db_name  \ -e  DB_USER=sample_db_user  \ -e  DB_PASS=sample_db_pass  \ -p 222:22 \ -p 7331:7331 \ -p 9292:9292 \ --name arachni \ arachni/arachni:latestRUn using docker-compose: version: '3'services: postgres:  image: postgres:9. 6  container_name: postgres  restart: always  environment:   POSTGRES_DB: arachni   POSTGRES_USER: test_username   POSTGRES_PASSWORD: test_username   PGDATA: /var/lib/postgresql/data/pgdata  volumes:   - . /cache/postgres/data/:/var/lib/postgresql/data/pgdata  ports:   -  5432:5432  arachni:  image: arachni/arachni:latest  conatiner_name: arachni  environment:   DB_ADAPTER: postgresql   DB_HOST: postgres   DB_NAME: arachni   DB_USER: test_username   DB_PASS: test_username  ports:   -  7331:7331    -  9292:9292    -  222:22   depends_on:   - postgres3. Running as a self contained package: 4. Using Web UI: "
    }, {
    "id": 28,
    "url": "http://0.0.0.0:4000/Running-Jekyll-in-Docker/",
    "title": "Jenkins - Upgrade Jenkins",
    "body": "2019/06/27 - Running Jekyll in DockerAccording to the official documentation og jekyll, Jekyll is a blog-aware, static site generator in Ruby and in order to install it you need to ensure that you have the  correct version of Ruby installed RubyGems installed GCC / Make installedIf you’re not familiar with these tools (ruby , gem, bundle, …. ) then getting up and running can be time consuming. But if you are familiar with docker run command is the only pre requisite to make app up and running with the jekyll/jekyll docker image. ##Prerequisites  docker docker-composeCreate the jekyll app: export JEKYLL_VERSION=3. 8mkdir -p $PWD/path/of/new/app; cd $PWD/path/of/new/appdocker run --rm --volume= $PWD:/srv/jekyll  -it jekyll/jekyll:$JEKYLL_VERSION jekyll new . What happened here ?:  We’ve started a docker jekyll container We’ve mounted the current folder as /srv/jekyll in the container We’ve passed the jekyll new command A new site was created in the current folder by the containerBuild the app: docker run --rm --volume= $PWD:/srv/jekyll  -it jekyll/jekyll:$JEKYLL_VERSION jekyll buildRUN:  create a docker-compose file for the applicationcat &lt;&lt; EOF &gt; docker-compose. yamlversion: '3'services: site:  container_name: platformops  command: jekyll serve --watch --drafts  image: jekyll/jekyll:latest  volumes:   - $PWD:/srv/jekyll  ports:   - 4000:4000EOF rundocker-ompose up -dApplication will be running on http://localhost:4000 or http://127. 0. 0. 1:4000 Install Gems: Option #1 : Post running, if we want to install anything manually: docker exec -ti platformops gem install  jekyll-theme-hydeout  Oprion #2 : If you want to deploy automatically, update `Gemfile’: group :jekyll_plugins do  gem  jekyll-feed ,  ~&gt; 0. 6   gem  jekyll-gist ,  ~&gt; 1. 4   gem  jekyll-paginate ,  ~&gt; 1. 1   gem  jekyll-theme-hydeout ,  ~&gt; 3. 4   endNext, in our _config. yml file, we’ll enable pagination, set the theme to jekyll-theme-hydeout add add some plugins paginate:5# Build settingsmarkdown: kramdowntheme: jekyll-theme-hydeoutplugins: - jekyll-feed - jekyll-gist - jekyll-paginate restart the service docker-compose downdocker-compose up -d"
    }, {
    "id": 29,
    "url": "http://0.0.0.0:4000/Run-commands-in-open-jdk-docker-container/",
    "title": "Open JDK docker container commands",
    "body": "2019/06/27 - Run commands in open jdk docker containerExample :  container name : platformops    to enter into the open jdk container   docker exec -it platformops /bin/sh     run the commands as required example echo $USER  "
    }, {
    "id": 30,
    "url": "http://0.0.0.0:4000/Play-with-AWS-EBS-volume/",
    "title": "AWS EBS Volmes - Create and attach the EBS volume with mounting",
    "body": "2019/06/27 - Create Volume from console:  Login to AWS console Goto menu Services -&gt; Compute -&gt; EC2 -&gt; In Left Sidebar under Elastic Block Store -&gt; click on Volume -&gt; Create Volume Fill the following parameterAttach a volume:  Select the created volume, right click and select the “attach volume” option.  Note: Volume and EC2 instance need to be in the same availability zone. Mount to the folder:    Now, login to your ec2 instance and list the available disks   `lsblk’   The above command will list the disk you attached to your instance     Check if the volume has any data   sudo file -s /dev/xvdf or `sudo file -s /dev/nvme1n1’   If the above command output shows “/dev/xvdf: data”, it means your volume is empty.     Format the volume to ext4 filesystem   sudo mkfs -t ext4 /dev/xvdf or sudo mkfs -t ext4 /dev/nvme1n1     Create a directory of your choice to mount our new ext4 volume. I am using the name “/var/avolume”   mkdir -p /var/avolume     Mount the volume to “/var/avolume” directory   mount /dev/nvme1n1 /var/avolume   cd into newvolume directory and check the disk space for confirming the volume mount.    cd /var/avolume df -h .     The above command would show the free space in the newvolume directory     To unmount the volume   unmount /dev/nvme1n1  "
    }, {
    "id": 31,
    "url": "http://0.0.0.0:4000/Multinode-to-single-node-Elasticsearch-Dump-Manually/",
    "title": "Elasticsearch - Dumping documents from multinode to single node",
    "body": "2019/06/27 - Elasticsearch three node cluster:: Elasticsearch is running as three node cluster, task is to copy and restore the multinode to single node cluster. node 1 :  http://node1:9300, http://node1:9200 node 2 :  http://node2:9300, http://node2:9200 node 3 :  http://node2:9300, http://node3:9200 As the shards getting distributed between nodes so no single node will have the complete data. When we manually copy and restore to single node instance there will be an unassigned shards of each node. Follow these steps to restore from multi node to single node.  Create the single node cluster using the docker-compose filecluster. name: wsindex#node. name:  wsnode #index. number_of_shards: 1#index. number_of_replicas: 0network. bind_host: 0. 0. 0. 0#network. host: 0. 0. 0. 0#discovery. zen. ping. multicast. enabled: falsecluster. routing. allocation. disk. threshold_enabled: true cluster. routing. allocation. disk. watermark. flood_stage: 200mbcluster. routing. allocation. disk. watermark. low: 500mb cluster. routing. allocation. disk. watermark. high: 300mbversion: '2'services:  wsindex-elasticsearch:    container_name: wsindex-elasticsearch    image: elasticsearch:2. 4. 1    environment:      -  ES_JAVA_OPTS=-Xms2g -Xmx2g     volumes:      - /var/db/elasticsearch/data:/usr/share/elasticsearch/data      - . /elasticsearch-conf. yml:/usr/share/elasticsearch/config/elasticsearch. yml    ports:      - 9200:9200      - 9300:9300 Copy the folder from node 1, with the scp -r /var/db/node1/elasticsearch/** /var/db/cassandra Start the cluster using docker-compose up -d By default, Elasticsearch will re-assign shards to nodes dynamically. with unassigned shards.  Check with the shards with curl -X GET  localhost:9200/_cat/shards  Number of nodes in the cluster was three so there was no extra node to create the replica, and restore the unassigned indexes, So the health was turning to red. Created the index with settings property and set the number_of_replicas as 0. curl -XPUT 'localhost:9200/_settings' -d '{   index  : {     number_of_replicas  : 0  }}' Check with shards again and note down the number of unassigned node shards Manually copy the shards which are unassigned from node 2 or node 3 Example, copy index client shards 2, 4scp -r /var/db/node2/data/wsindex/nodes/0/indices/client/2 /var/db/elasticsearch/data/wsindex/nodes/0/indices/client/scp -r /var/db/node2/data/wsindex/nodes/0/indices/client/4 /var/db/elasticsearch/data/wsindex/nodes/0/indices/client/ Restart the elasticsearch docker-compose down and docker-compose up -d Check with the shards and see if any unassigned shards exist and repeat the same as above.  When we are done with restoring the shards, node health will be turned into the greenMissing shards can be copied manually to the folder. However, if you’ve disabled shard allocation (perhaps you did a rolling restart and forgot to re-enable it), you can re-enable shard allocation. # v0. 90. x and earliercurl -XPUT 'localhost:9200/_settings' -d '{   index. routing. allocation. disable_allocation : false}'# v1. 0+curl -XPUT 'localhost:9200/_cluster/settings' -d '{   transient  : {     cluster. routing. allocation. enable  :  all   }}'Elasticsearch will then reassign shards as normal. This can be slow, consider raising indices. recovery. max_bytes_per_sec and cluster. routing. allocation. node_concurrent_recoveries to speed it up. If you’re still seeing issues, something else is probably wrong, so look in your Elasticsearch logs for errors. If you see EsRejectedExecutionException your thread pools may be too small. Finally, you can explicitly reassign a shard to a node with the reroute API. # Suppose shard 4 of index  my-index  is unassigned, so you want to# assign it to node search03:curl -XPOST 'localhost:9200/_cluster/reroute' -d '{   commands : [{     allocate : {       index :  my-index ,       shard : 4,       node :  search03 ,       allow_primary : 1    }  }]}'"
    }, {
    "id": 32,
    "url": "http://0.0.0.0:4000/Jenkins-email-build-log-output/",
    "title": "CICD Jenkins - Send email with default content",
    "body": "2019/06/27 - Send email with default content as the build outputPrerequisite Plugins: -Email-ext plugin Steps:  Create new job with freestyle [Optional]In Source Code Management section configure the git if required Configure the build section with type of build   Post-build Actions select Editable email notification configue the following properties   Project Recipient List: email@email. com,example@example. example   Project Reply-To List: no-reply@domain. com   Content Type: Select as required   Default Subject: Subject   Default Content:     Option1: Content Type - Text -&gt; `${BUILD_LOG_EXCERPT, start= ^Start , end= ^End }`  Option2: Content Type - html -&gt; `&lt;pre&gt;${BUILD_LOG_EXCERPT, start= ^Start , end= ^End }&lt;/pre&gt;`    Save and testExample: How to send build output as email to the specific email?  Execute shellecho  Start git log --since= 1 week ago  --pretty=format:'%cd %&lt;(20)%an %s' --date=format:'%Y-%m-%d %H:%M:%S'echo  End    Post-build Actions select Editable email notification configue the following properties   Project Recipient List: jinna. balu@platform-ops. com   Project Reply-To List: admin@platform-ops. com   Content Type: Select as required   Default Subject: Developers Weekly Progress   Default Content:```bashHi All,Here is the feature and bug progress of the week  ${BUILD_LOG_EXCERPT, start= ^Start , end= ^End }RegardsPlatform Ops Admin```  Save"
    }, {
    "id": 33,
    "url": "http://0.0.0.0:4000/Git-Cheet-Sheet/",
    "title": "Git - Git cheetsheet",
    "body": "2019/06/27 - Git Cheetsheet shortform git commandsalias g='git'  get a list of all commit messages for a repogit log --pretty=format:'%s'  find the nearest parent branch of the current git branchgit show-branch -a | grep '\*' | grep -v git rev-parse –abbrev-ref HEAD | head -n1 | sed 's/. *\[\(. *\)\]. */\1/' | sed 's/[\^~]. *//'  push changes to an empty git repository for the first timegit push --set-upstream origin master  delete first 10 branches of remote excluding mastergit branch -a | grep  remotes/origin  | grep -v master | sed 's/^[ *]*//' | sed 's/remotes\/origin\///' | head -n10 | sed 's/^/git push origin :/'  Remove + and - from start of diff linesgit diff --color | sed  s/^\([^-+ ]*\)[-+ ]/\\1/  | less -r  clear out git hooksfind . git/hooks -type l -exec rm {} \; &amp;&amp; find . githooks -type f -exec ln -sf . . /. . /{} . git/hooks/ \;  remove untracked files in a git repositorygit status -su | cut -d' ' -f2- | tr '\n' '\0' | xargs -0 rm  get most modified files and countsgit log --all -M -C --name-only --format='format:'  $@  | sort | grep -v '^$' | uniq -c | sort | awk 'BEGIN {print  count\tfile } {print $1  \t  $2}' | sort -g  Locally checkout all remote branches of a repositorygit branch -r | cut -d '/' -f2 | grep -Ev '( |master)' | xargs -Ibranch git checkout -b branch origin/branch  Open current Git repository URL      open git remote -v   awk ‘/fetch/{print $2}’   sed -Ee ‘s#(git@   git://)#http://#’ -e ‘s@com:@com/@’| head -n1    Remove Git from current projectfind . -name '. git' -exec rm -rf {} \;  Remove all new filesfor file in $(git status | grep  new file  | sed  s/#\tnew file:// ); do git rm --cached $file; done  Delete all remote branchesfor remote_branch in $(git ls-remote); do if [[ $remote_branch =~ . *(feature/MAGENTA-([0-9|^130]). +). * ]]; then git push origin :${BASH_REMATCH[1]}; fi; done  Removes all local branchfor branch in $(git branch | grep  feature/MAGENTA- ); do git branch -D $branch; done  get list of followers from github usernamecurl -s https://api. github. com/users/username/followers | grep '\ login\ ' | sed -e's/[,| |:]//g' | awk '{print $(NF)}' | sort  git commit random aliasgit config --global alias. commit-random '!git commit -m  $(curl -s http://whatthecommit. com/index. txt) ' usage: git commit-random  get list of users public reposcurl  https://api. github. com/users/usernamehere/repos?type=owner&amp;sort=updated  -s | sed -En 's| name :  (. +) ,|\1|p' | tr -d ' '  count relevant lines of shell code in a git repoegrep -v '^\s*($|#)' $(git grep -l '#!/bin/. *sh' *) | wc -l  push all remotesfor i in git remote; do git push $i; done;  cherry pick range of commits, starting from the tip of ‘master’, into ‘preview’ branchgit rev-list --reverse --topo-order master. . . | while read rev; do git checkout preview; git cherry-pick $rev || break; done  create tracking branches for all remote branchesgit branch -a | grep -v HEAD | perl -ne 'chomp($_); s|^\*?\s*||; if (m|(. +)/(. +)| &amp;&amp; not $d{$2}) {print qq(git branch --track $2 $1/$2\n)} else {$d{$_}=1}' | csh -xfs;  git reset newly added files      for f in git status   grep new   awk ‘{print $3}’; do git reset HEAD $f ; done    git reset newly added filesgit reset HEAD -- $(git status | awk '/new file:/{print $3}')  pull latest of all submodulesgit submodule foreach git pull origin master  show a git log with offsets relative to HEADgit log --oneline | nl -v0 | sed 's/^ \+/&amp;HEAD~/'  list offsets from HEAD with git logo=0; git log --oneline | while read l; do printf  %+9s %s\n   HEAD~${o}   $l ; o=$(($o+1)); done | less  diff the last 2 commitsgit diff $(git log --pretty=format:%h -2 --reverse | tr  \n     )  reset the last modified time for each file in a git repo to its last commit timegit ls-files | while read file; do echo $file; touch -d $(git log --date=local -1 --format= @%ct   $file )  $file ; done  get author and email of a commitgit --no-pager show -s --format='%an &lt;%ae&gt; on %cd' --date=short {commithash}  information about an author by giving it’s name or emailgit log -i -1 --pretty= format:%an &lt;%ae&gt;\n  --author= $1   List all files ever existedgit log --pretty=format: --name-status $@ | cut -f2- | sort -u  commit all changesgit add -A &amp;&amp; git commit -av  print git commit historygit log --oneline --decorate | nl | sort -nr | nl | sort -nr | cut --fields=1,3 | sed 's/([^)]*)\s//g'  print git commit historygit log --oneline --decorate | tac | nl | tac | sed 's/([^)]*)\s//g'  find the date of the first commit in a repogit log --pretty=format:'%ad' | tail -1  delete all local git branches that have been mergedgit branch --merged | grep -v  \*  | xargs -n 1 git branch -d  delete all git branches except mastergit branch | egrep -v ^master$ | sed 's/^[ *]*//' | sed 's/^/git branch -D /' | bash    delete all git branches except mastergit branch | grep -v “master” | sed ‘s/^[ ]//’ | sed ‘s/^/git branch -D /’ | bash     delete all git branches except mastergit checkout master; git branch | sed -e ‘/master/d’ -e ‘s/^/git branch -D /’ | bash     export current repo to zip archivegit archive -o “${PWD##*/}. zip” HEAD     figure out what pull requests are in your current branch (staging) but not yet in mastergit log HEAD…origin/master –pretty=oneline | grep pull     remove missing filesgit ls-files -d -z | xargs -0 git update-index –remove     list authors of a repogit shortlog -sn –all | cut -f2 | cut -f1 -d’ ‘     remove file from repo historygit filter-branch -f –tree-filter ‘rm -rf filename. py’ HEAD     list repos by usernamecurl “https://api. github. com/users/username/repos?type=owner&amp;sort=updated” -s | sed -En ‘s|”name”: “(. +)”,|\1|p’ | awk ‘{print $1}’     fetch all git remotes for a repogit branch -r | awk -F’/’ ‘{print “git fetch “$1,$2}’ | xargs -I {} sh -c {}     add a taggit tag -a 1. 2 -m “Version 1. 2 Stable”     show which branches are tracking whatgit for-each-ref –format=’%(refname:short)’ refs/heads/* | while read b; do if r=$(git config –get branch. $b. remote); then m=$(git config –get branch. $b. merge); echo “$b -&gt; $r/${m##*/}”; fi; done     push tagsgit push –tags     download all files from a gist without gitcurl -L https://gist. github. com/username/gistid/download | tar -xvz –strip-components=1     delete a local branchgit branch -d branchname     delete a remote branchgit push origin –delete branchname     list props for repogit log -i –grep props | egrep -io ‘props (to )?[a-z0-9_-]’ | sed ‘s/. //’ | sort | uniq -c | sort -k1nr     Undo your last commit, but don’t throw away your changesgit reset –soft HEAD^     Delete all local branches that have been merged into HEADgit branch -d git branch --merged | grep -v '^*' | grep -v 'master' | tr -d '\n'     credit author on last commitgit commit –amend –author “$1 &lt;$2&gt;” -C HEAD     Show the diff of everything you haven’t pushed yet. branch=$(git rev-parse –abbrev-ref HEAD) git diff origin/$branch. . HEAD     determine current branchgit branch | awk ‘/*/{print $2}’     check which branches had the latest commitsgit for-each-ref –sort=-committerdate –format=’%(refname:short) %(committerdate:short)’     search all commit messages for a stringgit rev-list –all | xargs git grep -F ‘string’     create a git. io short urlcurl -s -F “url=http://github. com/twitter” -i http://git. io | sed -n ‘s/Location:. * //p’     find the most verbs used in commit messagesgit log –pretty=format:’%s’ | cut -d “ “ -f 1 | sort | uniq -c | sort -nr     find the most verbs used in commit messagesgit log –oneline | awk ‘{ print $2; }’ | sort | uniq -c | sort -r     get current author and email of the repogit log -1 –pretty=”format:%an &lt;%ae&gt;” –author=”$1”     verify all packed objects and find the 5 biggest onesgit verify-pack -v . git/objects/pack/*. idx | sort -k 3 -n | tail -5     delete all tagsfor t in git tag do; git push origin :$t; git tag -d $t; done     compress all reposfind . -path ‘*. git/config’ -execdir git gc –aggressive \;     remove . DS_Store from the repository you happen to staging by mistakefind . -name . DS_Store -exec git rm –ignore-unmatch –cached {} +     Delete all local branches that have been merged into HEAD. git branch -d git branch --merged | grep -v '^*' | grep -v 'master' | tr -d '\n'     Credit an author on the last commitgit commit –amend –author “John Doe john@doe. com” -C HEAD     pretty git loggit log –graph –pretty=format:’%Cred%h%Creset %an: %s - %Creset %C(yellow)%d%Creset %Cgreen(%cr)%Creset’ –abbrev-commit –date=relative     delete local files that have been removed from git repogit status | grep deleted | awk ‘{$1=$2=  ; print $0}’ | perl -pe ‘s/^[ \t]*//’ | sed ‘s/ /\\ /g’ | xargs git rm     list all files ever added to a git repogit log –name-status –oneline –all | grep -P “^[A|M|D]\s” | awk ‘{print $2}’ | sort | uniq     get current branchgit branch | grep “^” | sed ‘s/ //g’     stage manually deleted filesgit status | grep deleted | sed ‘s/deleted://g’ | sed ‘s/[#| ]//g’ | xargs git rm     show path to the root of the repogit rev-parse –show-toplevel     recommit last commitLAST_MESSAGE=git log -1 --pretty= format:%s ; git commit -m “$LAST_MESSAGE” –amend –date “date”     Get a list of all TODO/FIXME tasks left to be done in your projectalias tasks=’grep –exclude-dir=. git -rEI “TODO|FIXME” . 2&gt;/dev/null’     edit your gitignore from anywhere in your repovim $(git rev-parse –show-toplevel)/. gitignore     simple single-lined git loggit log –pretty=oneline –abbrev-commit     Lint Git unstaged PHP filesgit status -s | grep -o ‘ \S*php$’ | while read f; do php -l $f; done     100% rollback files to a specific revisiongit reset –hard &amp;&amp; git clean -f     Print out the contents of a Git repository (useful for broken repositories)find . git/objects -type f -printf “%P\n” | sed s,/,, | while read object; do echo “=== $obj $(git cat-file -t $object) ===”; git cat-file -p $object; done     Show git branches by date - useful for showing active branchesgit for-each-ref –sort=’-authordate’ –format=’%(refname)%09%(authordate)’ refs/heads | sed -e ‘s-refs/heads/–’     git log with color and pathalias gitlog=’git log -10 –graph –date-order -C -M –pretty=format:”%C(yellow)%h%C(reset) - %C(bold green)%ad%C(reset) - %C(dim yellow)%an%C(reset) %C(bold red)&gt;%C(reset) %C(white)%s%C(reset) %C(bold red)%d%C(reset) “ –abbrev-commit –date=short’     open (in vim) all modified files in a git repositorygit status –porcelain | sed -ne ‘s/^ M //p’ | tr ‘\n’ ‘\0’ | tr -d ‘”’ | xargs -0 vim     open (in vim) all modified files in a git repositoryvim git status --porcelain | sed -ne 's/^ M //p'     open (in vim) all modified files in a git repositoryvim git status | grep modified | awk '{print $3}'     open (in vim) all modified files in a git repositoryvim -p git --porcelain | awk {print $2}     stage all manually deleted filesfor x in git status | grep deleted | awk '{print $3}'; do git rm $x; done     generate file list modified since last commit and export to tar filegit diff-tree -z -r –no-commit-id –name-only –diff-filter=ACMRT COMMID_HASH | xargs -0 tar -rf list. tar     export unpushed files listgit log -z origin/master. . master –name-only –pretty=”format:” | sort -zu | xargs -0 tar -rf list. tar     Count the lines of each file extenion in a list of filesgit ls-files | xargs wc -l | awk -F ‘ +|\. |/’ ‘{ sumlines[$NF] += $2 } END { for (ext in sumlines) print ext, sumlines[ext] }’     Show git commit historygit reflog show | grep ‘}: commit’ | nl | sort -nr | nl | sort -nr | cut –fields=1,3 | sed s/commit://g | sed -e ‘s/HEAD@{[0-9]}://g’     Restore deleted file from GIT repositorygit checkout $(git rev-list -n 1 HEAD – “$file”)^ – “$file”     Number of commits per day in a git repogit log | grep Date | awk ‘{print “ : “$4” “$3” “$6}’ | uniq -c     Remove git branches that do not have a rmote tracking branch anymoregit branch -r | awk ‘{print $1}’ | egrep -v -f /dev/fd/0 &lt;(git branch -vv | grep origin) | awk ‘{print $1}’ | xargs git branch -d     Remove . git dirsfind . -name “. git” -type d -exec rm -rf {} \;     Top Ten of the most active committers in git repositoriesgit shortlog -s | sort -rn | head     git - create a local branch that tracks with the remote branchgit checkout -tb mybranch origin/mybranch     Prints per-line contribution per author for a GIT repositorygit ls-files | xargs -n1 git blame –line-porcelain | sed -n ‘s/^author //p’ | sort -f | uniq -ic | sort -nr     Git Tree Command with color and tag/branch namegit log –graph –oneline –all –decorate –color     Open the current project on Github by typing ghgit remote -v | grep fetch | sed ‘s/(. github. com)[:|/](. ). git (fetch)/\2/’ | awk {‘print “https://github. com/” $1’} | xargs open     Show git branches by date - useful for showing active branchesfor k in $(git branch | sed /*/d); do echo “$(git log -1 –pretty=format:”%ct” $k) $k”; done | sort -r | awk ‘{print $2}’     Update (pull commits from) all submodulesgit submodule foreach git pull –ff-only origin master     commit message generator - whatthecommit. comcurl http://whatthecommit. com/index. txt     Create tarball of files modified in gittar czf git_mods_circa_dec23. tgz –files-from &lt;(git ls-files -m)     Sequential revision numbers in Gitgit rev-list –reverse HEAD | awk “/$(git log -n 1 –pretty=”format:%h”)/ {print NR}”     commit message generator - whatthecommit. comcurl -s ‘http://whatthecommit. com/’ | grep ‘&lt;p&gt;’ | cut -c4-     Show git branches by date - useful for showing active branchesfor k in git branch|sed s/^. . //;do echo -e git log -1 --pretty=format: %Cgreen%ci %Cblue%cr%Creset   $k  --\t”$k”;done|sort     git Output remote origin from within a local repositorygit config –local –get remote. origin. url     delete local and remote git repos if merged into local mastergit branch | cut -c3- | grep -v “^master$” | while read line; do git branch -d $line; done | grep ‘Deleted branch’ | awk ‘{print $3;}’ | while read line; do git push :$line; done     Using Git, stage all manually deleted files. git add -u     Pull git submodules in parallel using GNU parallelparallel -j4 cd {}\; pwd\; git pull :::: &lt;(git submodule status | awk ‘{print $2}’)     bash script to zip a folder while ignoring git files and copying it to dropboxgit archive HEAD | gzip &gt; ~/Dropbox/archive. tar. gz     Push each of your local git branches to the remote repositorygit push origin –all     Deleting a remote git branch (say, by name ‘featureless’)git push origin :featureless     git-rm for all deleted files, including those with space/quote/unprintable characters in their filename/pathgit ls-files -z -d | xargs -0 git rm –     GIT: list unpushed commitsgit log –oneline . .     commit message generator - whatthecommit. comlynx -dump -nolist http://whatthecommit. com/|sed -n 2p     commit message generator - whatthecommit. comcurl -s http://whatthecommit. com | html2text | sed ‘$d’     commit message generator - whatthecommit. comcurl -s http://whatthecommit. com | sed -n ‘/&lt;p&gt;/,/&lt;\/p&gt;/p’ | sed ‘$d’ | sed ‘s/&lt;p&gt;//’     telling you from where your commit come fromfunction where(){ COUNT=0; while [ where_arg $1~$COUNT | wc -w == 0 ]; do let COUNT=COUNT+1; done; echo “$1 is ahead of “; where_arg $1~$COUNT; echo “by $COUNT commits”;};function where_arg(){ git log $@ –decorate -1 | head -n1 | cut -d ‘ ‘ -f3- ;}     Show the changed files in your GIT repogit status | perl -F’\s’ -nale ‘BEGIN { $a = 0 }; $a = 1 if $_ =~ /changed but not updated/i; print $F[-1] if ( $a &amp;&amp; -f $F[-1] )’     Search git repo for specified stringgit grep “search for something” $(git log -g –pretty=format:%h -S”search for something”)     Get first Git commit hashgit log –pretty=format:%H | tail -1     Get first Git commit hashgit log –format=%H | tail -1     List all authors of a particular git projectgit log –format=’%aN &lt;%aE&gt;’ | awk ‘{arr[$0]++} END{for (i in arr){print arr[i], i;}}’ | sort -rn | cut -d\ -f2-     See all the commits for which searchstring appear in the git diffgit log -p -z | perl -ln0e ‘print if /[+-]. *searchedstring/’     List every file that has ever existed in a git repositorygit log –all –pretty=format:” “ –name-only | sort -u     git pull all reposfind ~ -maxdepth 2 -name . git -print | while read repo; do cd $(dirname $repo); git pull; done     Add . gitignore files to all empty directories recursively from your current directoryfind . ( -type d -empty ) -and ( -not -regex . /. git. * ) -exec touch {}/. gitignore \;     Display condensed log in a tree-like format. git log –graph –pretty=oneline –decorate     List all authors of a particular git projectgit log –format=’%aN’ | sort -u     List all authors of a particular git projectgit shortlog -s | cut -c8-     Show git branches by date - useful for showing active branchesfor k in git branch|sed s/^. . //;do echo -e git log -1 --pretty=format: %Cgreen%ci %Cblue%cr%Creset   $k \t”$k”;done|sort     Move all files untracked by git into a directorygit clean -n | sed ‘s/Would remove //; /Would not remove/d;’ | xargs mv -t stuff/     Prints per-line contribution per author for a GIT repositorygit ls-files | while read i; do git blame $i | sed -e ‘s/^[^(](//’ -e ‘s/^([^[:digit:]])[[:space:]]+[[:digit:]]. */\1/’; done | sort | uniq -ic | sort -nr     Prints per-line contribution per author for a GIT repositorygit ls-files | xargs -n1 -d’\n’ -i git-blame {} | perl -n -e ‘/\s((. *?)\s[0-9]{4}/ &amp;&amp; print “$1\n”’ | sort -f | uniq -c -w3 | sort -r     Makes a project directory, unless it exists; changes into the dir, and creates an empty git repository, all in one commandgitstart () { if ! [[ -d “$@” ]]; then mkdir -p “$@” &amp;&amp; cd “$@” &amp;&amp; git init; else cd “$@” &amp;&amp; git init; fi }     git Revert files with changed mode, not contentgit diff –numstat | awk ‘{if ($1 == “0” &amp;&amp; $2 == “0”) print $3}’ | xargs git checkout HEAD     Show changed files, ignoring permission, date and whitespace changesgit diff –numstat -w –no-abbrev | perl -a -ne ‘$F[0] != 0 &amp;&amp; $F[1] !=0 &amp;&amp; print $F[2] . “\n”;’     Show (only) list of files changed by commitgit show –relative –pretty=format:’’ –name-only HASH     Stage only portions of the changes to a file. git add –patch     Show log message including which files changed for a given commit in git. git –no-pager whatchanged -1 –pretty=medium     search string in all revisionsfor i in git log --all --oneline --format=%h; do git grep SOME_STRING $i; done     git remove files which have been deletedgit ls-files -z –deleted | xargs -0 git rm     Show git branches by date - useful for showing active branchesfor k in git branch|perl -pe s/^. . //;do echo -e git show --pretty=format: %Cgreen%ci %Cblue%cr%Creset  $k|head -n 1\t$k;done|sort -r     add forgotten changes to the last git commitgit commit –amend     git remove files which have been deletedgit rm $(git ls-files –deleted)     git diff of files that have been staged ie ‘git add’edgit diff –cached     add untracked/changed items to a git repository before doing a commit and/or sending upstreamgit status|awk ‘/modified:/ { printf(“git add %s\n”,$3) }; NF ==2 { printf(“git add %s\n”,$2) }’|sh     Better git diff, word delimited and colorizedgit config alias. dcolor “diff –color-words”     Better git diff, word delimited and colorizedgit diff -U10|dwdiff –diff-input -c|less -R     Better git diff, word delimited and colorizedgit diff -U10 |wdiff –diff-input -a -n -w $’\e[1;91m’ -x $’\e[0m’ -y $’\e[1;94m’ -z $’\e[0m’ |less -R     Count git commits since specific commitgit log –pretty=oneline b56b83. . | wc -l     Count git commits since specific commitgit log –summary 223286b. . | grep ‘Author:’ | wc -l     Execute git submodule update in parallel with xargsgit submodule status | awk ‘{print $2}’ | xargs -P5 -n1 git submodule update –init     Incorporating a finished feature on developgit checkout develop; git merge –no-ff myfeature     Creating a feature branchgit checkout -b myfeature develop     My Git Tree Command!git log –graph –oneline –all     show git logginggit log –stat     Create a git archive of the latest commit with revision number as name of filegit archive HEAD –format=zip -o git rev-parse HEAD. zip     List files under current directory, ignoring repository copies. function have_here { find “${@:-. }” -type d ( -name . git -o -name . svn -o -name . bzr -o -name CVS -o -name . hg -o -name pycache ) -prune -o -type f -print; }     revert the unstaged modifications in a git working directorygit diff | git apply –reverse  #commit message generatorcurl -s http://whatthecommit. com/ | tr -s ‘\n’ ‘ ‘ | grep -so ‘p&gt;(. )&lt;/p’ | sed -n ‘s/. . (. )…. /\1/p’    random git commit messagegit-random(){ gitRan=$(curl -L -s http://whatthecommit. com/ |grep -A 1 “ c” |tail -1 |sed ‘s/&lt;p&gt;//’); git commit -m “$gitRan”; }     rename a branchgit branch -m old_branch new_branch     set upstream for existing branchgit branch –set-upstream /     checkout remote branchgit checkout -b test origin/test     pretty git commit loggit log –pretty=format:”%h %ad | %s%d [%an]” –graph –date=short     make git HEAD same as origin/mastergit reset –hard origin/master     delete a remote branchgit push origin :heads/branch_name     revert uncommited git changesgit reset –hard HEAD     add . gitignore to enable add empty directory to gitfor i in $(find . -type d -regex ``. /[^. ]. *’’ -empty); do touch $i”/. gitignore”; done;     list files between git commitsgit diff –name-only 4ce07ee 7cdf78b     list all branchesgit branch -a     install a new git repofunction gitinstall(){ git init; git remote add origin “$@”; git config branch. master. remote origin; git config branch. master. merge refs/heads/master; git pull;}     git recursive rmgit ls-files -d -z | xargs -0 git update-index –remove     undo last git commitgit reset –soft HEAD^     find deleted stashes and other lost commits in gitgit fsck –no-reflog | awk ‘/dangling commit/ {print $3}’     git apply patchgit format-patch -k –stdout rev1-1. . rev2 | git am -k -3     git catgit cat-file -p $(git ls-tree $1 “$2” | cut -d “ “ -f 3 | cut -f 1)     list unmerged filesgit ls-files -u|awk ‘{print $4}’|sort -u     list added files in the indexgit diff-index HEAD|awk ‘{print $5 “ “ $6}’|sed -n -e’s/^A //p’     print number of modified filesgit status –porcelain | cut -c 1-2 | grep M | wc -l | tr -d “ “     show all remote git branchesgit remote show origin     fancy git prompt  parse_git_branch() { git branch 2&gt; /dev/null | sed -e ‘/^[^]/d’ -e ‘s/ (. *)/(git::\1)/’} export PS1=”[\033]0;\h \w $(parse_git_branch) \007][[\033[01;35m]\h [\033[01;34m]\w [\033[31m]$(parse_git_branch)[\033[00m]]$ “    Recursively remove all untracked files in the tree. git clean -f     throw out all of your changes to existing files, but not new onesgit reset –hard     remove file from staging areagit rm –cached [file]     see diff of files in staging areagit diff –staged     see tracked filesgit ls-files     see a branch graphgit log –graph     see all tagsgit tag     see list of deleted filesgit ls-files -d     restore all deleted filesgit ls-files -d | xargs git checkout –     view commits not yet pushed to remotegit log –branches –not –remotes     difference between two branchesgit diff –stat –color master. . branch     see a list of all objects - git rev-list --objects --all     remove file from indexgit rm --cached filename. txt  "
    }, {
    "id": 34,
    "url": "http://0.0.0.0:4000/Dockerizing-a-Node.js-web-application/",
    "title": "Docker - dockerise the nodejs application",
    "body": "2019/06/27 - Main goal of this story is to dockerise the nodejs application. Assuming that you have come here after installing nodejs and docker. Here is github repo Check with the installations of nodejs and docker version nodejs -vdocker version Create a nodejs application (Skip this if you have running app) Dockerise nodejs applicationCreate a folder name app and use the same folder to create the nodejs application. : mkdir appcd app/Use the npm init command to create a package. json file for your application. For more information on how package. json works, see Specifics of npm’s package. json handling. npm init # Will ask you basic questions about your appThis command prompts you for a number of things, such as the name and version of your application. For now, you can simply hit RETURN to accept the defaults for most of them, with the following exception: package. json{ name :  dockerise-nodejs , version :  1. 0. 0 , description :  Dockerising NodeJS application , main :  index. js , scripts : { test :  echo \ Error: no test specified\  &amp;&amp; exit 1 }, repository : { type :  git , url :  git+https://github. com/JinnaBalu/dockerise-nodejs. git }, keywords : [], author :   , license :  ISC , bugs : { url :  https://github. com/JinnaBalu/dockerise-nodejs/issues }, homepage :  https://github. com/JinnaBalu/dockerise-nodejs#readme , dependencies : { express :  ^4. 16. 2 }}Now install Express in the app directory and save it in the dependencies list. npm install express --saveThen, create a index. js file that defines a web app using the Express. js framework and copy the following code into the file 'use strict';const express = require('express');// Constantsconst PORT = 8080;const HOST = '0. 0. 0. 0';// Appconst app = express();app. get('/', (req, res) =&gt; { res. send('Hello world\n');});app. listen(PORT, HOST);console. log(`Running on http://${HOST}:${PORT}`);Create empty file called Dockerfile, used for creating the docker imagetouch Dockerfile Open the Dockerfile in your favorite text editor and copy the following. FROM node:boronWORKDIR /usr/src/appCOPY package. json . RUN npm installCOPY . . EXPOSE 8080CMD [  npm ,  start  ]Create a . dockerignore file in the same directory as your Dockerfile with following content node_modulesnpm-debug. logGo to the directory that has your Dockerfile and run the following command to build the Docker image. The -t flag lets you tag your image so it’s easier to find later using the docker images command docker build -t &lt;image_name&gt; . # example : docker build -t nodejssample . List the docker images docker images Create a docker-compose. yml file version: '2'services: nodejs: image: nodejssample ports: - '8080:8080'docker-compose up -d"
    }, {
    "id": 35,
    "url": "http://0.0.0.0:4000/Delete-lines-usig-sed-command/",
    "title": "Linux - sed command",
    "body": "2019/06/27 - Delete lines usig sed command: In the following examples, the sed command removes the lines in file that are in a particular position in a file. Delete first line or header line: The d option in sed command is used to delete a line. The syntax for deleting a line is: sed 'Nd' fileHere N indicates Nth line in a file. In the following example, the sed command removes the first line in a file. sed '1d' fileunixfedoradebianubuntuDelete last line or footer line or trailer line: The following sed command is used to remove the footer line in a file. The $ indicates the last line of a file. sed '$d' filelinuxunixfedoradebianDelete particular line: This is similar to the first example. The below sed command removes the second line in a file. sed '2d' filelinuxfedoradebianubuntuDelete range of lines: The sed command can be used to delete a range of lines. The syntax is shown below:```bashsed ‘m,nd’ file Here m and n are min and max line numbers. The sed command removes the lines from m to n in the file. The following sed command deletes the lines ranging from 2 to 4: sed '2,4d' filelinuxubuntuDelete lines other than the first line or header line: Use the negation (!) operator with d option in sed command. The following sed command removes all the lines except the header line. sed '1!d' filelinuxDelete lines other than last line or footer line: ```bashsed ‘$!d’ fileubuntu Delete lines other than the specified range: sed '2,4!d' fileunixfedoradebianHere the sed command removes lines other than 2nd, 3rd and 4th. Delete first and last line: You can specify the list of lines you want to remove in sed command with semicolon as a delimiter. sed '1d;$d' fileunixfedoradebianDelete empty lines or blank lines: sed '/^$/d' fileThe ^$ indicates sed command to delete empty lines. However, this sed do not remove the lines that contain spaces. Sed Command to Delete Lines - Based on Pattern Match In the following examples, the sed command deletes the lines in file which match the given pattern. Delete lines that begin with specified character: sed '/^u/d' filelinuxfedoradebian^ is to specify the starting of the line. Above sed command removes all the lines that start with character ‘u’. Delete lines that end with specified character: sed '/x$/d' filefedoradebianubuntu$ is to indicate the end of the line. The above command deletes all the lines that end with character ‘x’. ####Delete lines which are in upper case or capital letters```bashsed ‘/^[A-Z]*$/d’ file Delete lines that contain a pattern: sed '/debian/d' filelinuxunixfedoraubuntuDelete lines starting from a pattern till the last line: sed '/fedora/,$d' filelinuxunixHere the sed command removes the line that matches the pattern fedora and also deletes all the lines to the end of the file which appear next to this matching line. Delete last line only if it contains the pattern: sed '${/ubuntu/d;}' filelinuxunixfedoradebianHere $ indicates the last line. If you want to delete Nth line only if it contains a pattern, then in place of $ place the line number. Note: In all the above examples, the sed command prints the contents of the file on the unix or linux terminal by removing the lines. However the sed command does not remove the lines from the source file. To Remove the lines from the source file itself, use the -i option with sed command. sed -i '1d' fileIf you dont wish to delete the lines from the original source file you can redirect the output of the sed command to another file. sed '1d' file &gt; newfile"
    }, {
    "id": 36,
    "url": "http://0.0.0.0:4000/Clean-tumbstones-in-cassandra/",
    "title": "Clean tumbstones in cassandra",
    "body": "2019/06/27 - Clean tumbstones in cassandra   Get the GC_GRACE_SECONDS value of the table, store it in some file.     Alter to reduce the GC_GRACE_SECONDS to 30  alter table student with GC_GRACE_SECONDS = 30; Wait for 30-60 seconds to cleanup the tumbstones and continue to atlter to the last value.  Replace it back with actual valuealter table student with GC_GRACE_SECONDS = 86400; "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});


    
function lunr_search(term) {
    $('#lunrsearchresults').show( 1000 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-secondary btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
</script>
<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>




<form class="bd-search hidden-sm-down" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
<input type="text" class="form-control bg-graylight border-0 font-weight-bold"  id="lunrsearch" name="q" value="" placeholder="Type and hit enter..."> 
</form>
        </ul>
        <ul class="navbar-nav ml-auto align-items-center">
            
            <li class="nav-item">
                <a class="nav-link" href="/categories.html">Categories</a>
            </li>
            
            <li class="nav-item">
                <a class="nav-link" href="/index.html#Explore">Post</a>
            </li>
            
            <li class="nav-item">
                <a class="nav-link" href="/contact.html">Contact</a>
            </li>
            
            <li class="nav-item">
                <a class="nav-link" href="/about.html">
                    <img class="rounded-circle mr-2" src="/assets/images/jinnabalu.ico" width="30"><span
                        class="align-middle">About</span></a>
            </li>
            <li class="nav-item dropdown">
                <a class="nav-link" href="#" id="dropdown02" data-toggle="dropdown" aria-haspopup="true"
                    aria-expanded="false">
                    <svg style="margin-top:10px;" class="_3DJPT" version="1.1" viewbox="0 0 32 32" width="21"
                        height="21" aria-hidden="false" data-reactid="71">
                        <path
                            d="M7 15.5c0 1.9-1.6 3.5-3.5 3.5s-3.5-1.6-3.5-3.5 1.6-3.5 3.5-3.5 3.5 1.6 3.5 3.5zm21.5-3.5c-1.9 0-3.5 1.6-3.5 3.5s1.6 3.5 3.5 3.5 3.5-1.6 3.5-3.5-1.6-3.5-3.5-3.5zm-12.5 0c-1.9 0-3.5 1.6-3.5 3.5s1.6 3.5 3.5 3.5 3.5-1.6 3.5-3.5-1.6-3.5-3.5-3.5z"
                            data-reactid="22"></path>
                    </svg>
                </a>
                <div class="dropdown-menu dropdown-menu-right shadow-lg" aria-labelledby="dropdown02">
                    <h4 class="dropdown-header display-4">Containerise anything and everything</h4>
                    <div class="dropdown-divider">
                    </div>
                    <span class="dropdown-item">
                       <style>
    .bmc-button img {
        width: 27px !important;
        margin-bottom: 1px !important;
        box-shadow: none !important;
        border: none !important;
        vertical-align: middle !important;
    }

    .bmc-button {
        line-height: 36px !important;
        height: 37px !important;
        text-decoration: none !important;
        display: inline-flex !important;
        color: #FFFFFF !important;
        background-color: #FF813F !important;
        border-radius: 3px !important;
        border: 1px solid transparent !important;
        padding: 1px 9px !important;
        font-size: 22px !important;
        letter-spacing: 0.6px !important;
        box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;
        -webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;
        margin: 0 auto !important;
        font-family: 'Cookie', cursive !important;
        -webkit-box-sizing: border-box !important;
        box-sizing: border-box !important;
        -o-transition: 0.3s all linear !important;
        -webkit-transition: 0.3s all linear !important;
        -moz-transition: 0.3s all linear !important;
        -ms-transition: 0.3s all linear !important;
        transition: 0.3s all linear !important;
    }

    .bmc-button:hover,
    .bmc-button:active,
    .bmc-button:focus {
        -webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;
        text-decoration: none !important;
        box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;
        opacity: 0.85 !important;
        color: #FFFFFF !important;
    }
</style>
<link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet"><a class="bmc-button d-block" target="_blank"
    href="https://www.buymeacoffee.com/RL2BZTU"><img
        src="https://bmc-cdn.nyc3.digitaloceanspaces.com/BMC-button-images/BMC-btn-logo.svg" alt="Buy me a coffee"><span
        style="margin-left:5px">Buy me a coffee</span></a>
                    </span>
                </div>
            </li>
        </ul>
    </div>
</nav>
  <div id="lunrsearchresults">
    <ul class="mb-0"></ul>
</div>

  <main role="main">
    <section class="bg-gray200 pt-5 pb-5">    
    <div class="container-fluid">
    	<div class="row justify-content-center">
    		<div class="col-md-8">
                
    			<article class="card">
                    
                 
                    
    			<div class="card-body">
                    
    				<h1 class="display-4">
    				    Dockerfile 
                    </h1>                    
                     
                    <small class="text-muted d-block mb-3">
                         
                            August 26, 2019 
                        
                        
                    </small>                    
                    
    				

                    
                    
                    
                    
                    
    				<!--  Don't edit anything here. Set your disqus id in _config.yml -->

<div id="comments" class="mt-5">
    <div id="disqus_thread">
    </div>
    <script type="text/javascript">
        var disqus_shortname = 'platform-ops-tech';
        var disqus_developer = 0;
        (function () {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>
        Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
    </noscript>
</div>
                    
    			</div>  
                    
    			</article>
                
                <div class="PageNavigation">
                  
                    <a class="prev" href="/Dockerise-html-page/"><i class="fa fa-angle-left"></i> </a>
                  
                  
                    <a class="next" href="/Docker-Image-Layers/"><i class="fa fa-angle-right"></i></a>
                  
                </div>
                
    		</div>
    	</div>
    </div>
</section>
  </main>

  <footer class="footer pt-5 pb-5 text-center bg-warning">
    <div class="container-fluid">
        <div class="row text-center text-xs-center text-sm-left text-md-left">
            <div class="col-xs-12 col-sm-3 col-md-3">
                <img class="img-fluid" src="/assets/images/logo.png">
            </div>
            <div class="col-xs-12 col-sm-3 col-md-9">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 col-md-6">
                        <h5>Platform Ops</h5>
                        <p>
                            Platform Ops, Articles from a platform engineer on Fullstack Development, Application Architecture, DevOps, Cloud Ops, Platform Ops, Docker, Dockerization, Containerisation, CICD Tools, Jenkins, Git, Gitlabs, Distributed Databases configuration, application zero downtime, reverse proxy, NGXIN and it covers each and every area of the application development and operations in the cloud.
                        </p>
                        <br>
                        <style>
    .bmc-button img {
        width: 27px !important;
        margin-bottom: 1px !important;
        box-shadow: none !important;
        border: none !important;
        vertical-align: middle !important;
    }

    .bmc-button {
        line-height: 36px !important;
        height: 37px !important;
        text-decoration: none !important;
        display: inline-flex !important;
        color: #FFFFFF !important;
        background-color: #FF813F !important;
        border-radius: 3px !important;
        border: 1px solid transparent !important;
        padding: 1px 9px !important;
        font-size: 22px !important;
        letter-spacing: 0.6px !important;
        box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;
        -webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;
        margin: 0 auto !important;
        font-family: 'Cookie', cursive !important;
        -webkit-box-sizing: border-box !important;
        box-sizing: border-box !important;
        -o-transition: 0.3s all linear !important;
        -webkit-transition: 0.3s all linear !important;
        -moz-transition: 0.3s all linear !important;
        -ms-transition: 0.3s all linear !important;
        transition: 0.3s all linear !important;
    }

    .bmc-button:hover,
    .bmc-button:active,
    .bmc-button:focus {
        -webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;
        text-decoration: none !important;
        box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;
        opacity: 0.85 !important;
        color: #FFFFFF !important;
    }
</style>
<link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet"><a class="bmc-button d-block" target="_blank"
    href="https://www.buymeacoffee.com/RL2BZTU"><img
        src="https://bmc-cdn.nyc3.digitaloceanspaces.com/BMC-button-images/BMC-btn-logo.svg" alt="Buy me a coffee"><span
        style="margin-left:5px">Buy me a coffee</span></a>
                    </div>
                    <div class="col-xs-12 col-sm-3 col-md-2 text-left">
                        <h5>Quick links</h5>
                        <ul class="list-unstyled quick-links">
                            <li>
                                <a class="nav-link" href="/categories.html">Categories</a>
                            </li>
                            <li>
                                <a class="nav-link" href="/index.html#Explore">Post</a>
                            </li>
                            <li>
                                <a class="nav-link" href="/contact.html">Contact</a>
                            </li>
                            <li>
                                <a class="nav-link" href="/about.html">
                                    <img class="rounded-circle mr-2" src="/assets/images/jinnabalu.ico" width="30"><span
                                        class="align-middle">About</span></a>
                            </li>
                        </ul>
                    </div>
                    <div class="col-xs-12 col-sm-3 col-md-4">
                        <h5>Containerisation</h5>
                        <h3>
    
    
    <span class="badge badge-pill badge-light">
        <a class="smoothscroll text-dark" href="/categories#analytics">
            Analytics
        </a>
    </span>
    
    <span class="badge badge-pill badge-light">
        <a class="smoothscroll text-dark" href="/categories#application">
            Application
        </a>
    </span>
    
    <span class="badge badge-pill badge-light">
        <a class="smoothscroll text-dark" href="/categories#databases">
            Databases
        </a>
    </span>
    
    <span class="badge badge-pill badge-light">
        <a class="smoothscroll text-dark" href="/categories#devops">
            DevOps
        </a>
    </span>
    
    <span class="badge badge-pill badge-light">
        <a class="smoothscroll text-dark" href="/categories#messaging">
            Messaging
        </a>
    </span>
    
    <span class="badge badge-pill badge-light">
        <a class="smoothscroll text-dark" href="/categories#monitoring">
            Monitoring
        </a>
    </span>
    
    <span class="badge badge-pill badge-light">
        <a class="smoothscroll text-dark" href="/categories#security">
            Security
        </a>
    </span>
    
    <span class="badge badge-pill badge-light">
        <a class="smoothscroll text-dark" href="/categories#storage">
            Storage
        </a>
    </span>
    
</h3>
                    </div>
                </div>
                <hr>
                <div class="row">
                    <div class="col-6 text-left">
                        <p>
                            &copy 2019 Platform Operations
                            <a target="_blank" class="text-dark"
                                href="https://www.wowthemes.net/pintereso-free-bootstrap-jekyll-theme/">
                                Made with <u>Pintereso</u>
                            </a>
                        </p>
                    </div>
                    <div class="col-2">

                    </div>
                    <div class="col-4 text-right">
                        <a target="_blank" href="https://www.linkedin.com/in/jinna-balu-20368995/" class="text-dark">
                            <i class="fab fa-linkedin"></i>
                        </a> |
                        <a target="_blank" href="https://github.com/JinnaBalu" class="text-dark">
                            <i class="fab fa-github"></i>
                        </a> |
                        <a target="_blank" href="https://twitter.com/JinnaBalu" class="text-dark">
                            <i class="fab fa-twitter"></i>
                        </a> |
                        <a target="_blank" href="https://stackoverflow.com/users/4348824/jinna-balu" class="text-dark">
                            <i class="fab fa-stack-overflow"></i>
                        </a> |
                        <a class="text-muted" href="http://0.0.0.0:4000/privacy-policy.html">
                            Privacy Policy
                        </a>
                        |
                        <a class="text-muted" target="_blank" href="http://0.0.0.0:4000/license.html">
                            License
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</footer>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
    integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js"
    integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T"
    crossorigin="anonymous"></script>

<script src="/assets/js/theme.js"></script>

<script src="/assets/js/lunr.js"></script>
<!-- Pinterest Script, nothing for you to replace here  -->
<script async defer src="//assets.pinterest.com/js/pinit.js"></script>

<!-- Cookie Consent, nothing for you to replace here. Remove it if you want  -->
<link rel="stylesheet" type="text/css"
    href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.js"></script>
<script>
    window.addEventListener("load", function () {
        window.cookieconsent.initialise({
            "palette": {
                "popup": {
                    "background": "#eb6c44",
                    "text": "#ffffff"
                },
                "button": {
                    "background": "#f5d948"
                }
            },
            "position": "bottom-left",
            "content": {
                "href": "http://0.0.0.0:4000/privacy-policy.html"
            }
        })
    });
</script>


<script type='text/javascript'
    src='https://platform-api.sharethis.com/js/sharethis.js#property=5d8ed2f0ddd24e0019459c33&product=sticky-share-buttons'
    async='async'></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-143812938-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-143812938-1');
</script>
  <script
    type="text/javascript">window.$crisp = []; window.CRISP_WEBSITE_ID = "f2e8c87f-f50f-4ebb-90fe-b45fa60e1724"; (function () { d = document; s = d.createElement("script"); s.src = "https://client.crisp.chat/l.js"; s.async = 1; d.getElementsByTagName("head")[0].appendChild(s); })();</script>
</body>

</html>